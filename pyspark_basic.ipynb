{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3PmM1ucvLbsZMN1S61+OS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiwari666/pyspark/blob/main/pyspark_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **pyspark Introduction:**\n",
        "\n",
        "PySpark is a Python API for Apache Spark, a distributed computing system. The name \"PySpark\" is a combination of \"Python\" and \"Spark.\" It allows us to write Spark applications using Python, leveraging the capabilities of Spark's distributed computing framework.\n",
        "\n",
        "\n",
        "PySpark can interact with various data sources, including SQL databases, through JDBC (Java Database Connectivity) drivers. This allows us to read data from and write data to SQL databases using PySpark."
      ],
      "metadata": {
        "id": "j5tNGfhwzlkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxQR86da0p1r",
        "outputId": "fd5058cf-806b-42e6-acb6-cd026d7e4658"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "_tR14-9a0yoh"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# two different ways of defiing SparkSession in pyspark:\n",
        "In PySpark, we can define a SparkSession using two different approaches:\n",
        "\n",
        "A) Using SparkSession.builder:USED IN Spark 2.0 and later versions--must use this one.\n",
        "\n",
        "B) Using SparkContext: used in Spark versions prior to 2.0.--Deprecated.\n",
        "\n",
        "\n",
        "# Conclusion:\n",
        "\n",
        "Using SparkSession.builder is recommended as it offers more flexibility and features compared to directly using SparkContext for creating a session. Also, using SparkSession.builder is the standard way of creating a session in Spark 2.0 and later versions."
      ],
      "metadata": {
        "id": "qyyZK0z5DW3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "EyJWPZ6R2NgI"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How we define session matters:\n",
        "# creating a SparkSession in PySpark. SparkSession is the entry point to Spark SQL and DataFrame API.\n",
        "sparkSession=SparkSession.builder.appName('Exercise').getOrCreate()"
      ],
      "metadata": {
        "id": "ize_ZBAJ2T9u"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative\n",
        "# SparkSession = SparkSession.builder \\\n",
        "#     .appName(\"PySparkOperations\") \\\n",
        "#     .getOrCreate()"
      ],
      "metadata": {
        "id": "4BYf6-Sw8N3V"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparkSession"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "h851CZ682q9W",
        "outputId": "bf661211-b8b9-48c0-f18b-5ab9714f55e9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fee8cb424a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://67f328a3ca10:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=sparkSession.read.csv('test1.csv')\n",
        "df_pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eipkiqva2r78",
        "outputId": "e4194b94-18a9-40b9-dbd5-98d3d02d12a9"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different ways of reading columns in pyspark:\n",
        "\n",
        "# But we must write \"('header','true')\" while reading the data in the pyspark.\n",
        "\n",
        "# Columns : see important difference while writing \"('header','true')\"\n",
        "\n",
        "# we can see the differences in the immediate following codes.\n",
        "\n",
        "# Note: Only one method/ standard methos is only used in the session."
      ],
      "metadata": {
        "id": "L54T21QBCTxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  reading a CSV file into a DataFrame using PySpark.\n",
        "\n",
        "df_pyspark=sparkSession.read.option('header','true').csv('test1.csv')  # retains original column names"
      ],
      "metadata": {
        "id": "aF2whbgm3qBl"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # df_pyspark=SparkSession.read.csv('test1.csv') # gives _c0, _c1 as column names\n",
        "\n",
        "#   # Selecting columns by index\n",
        "# df_selected_col = df_pyspark.select('_c0', '_c1')\n",
        "\n",
        "#   # Show the selected columns\n",
        "# df_selected_col.show()"
      ],
      "metadata": {
        "id": "MmWq0i0aFpp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bL32ArV4AAR",
        "outputId": "319376d0-e600-49b4-c577-9e33997572b1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, age: string, Experience: string, Salary: string]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "ISOGIyPs4Btg",
        "outputId": "925c81a2-e252-46ca-814d-cddefdfd2c2f"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v39pu8_V4ZhU",
        "outputId": "9197e524-35f5-4aa6-bf83-7c202801287e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 31|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|       Jo| 23|         5| 25000|\n",
            "|      Sam| 21|         4| 28000|\n",
            "|       Li| 29|         1| 15000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying the schema of the DataFrame in PySpark. The schema defines the structure of the DataFrame, including column names and data types.\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdW1U_874cQM",
        "outputId": "ebde5019-df7b-4f80-f89d-4def2a67f7c6"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converts the PySpark DataFrame df_pyspark to a Pandas DataFrame df_pandas\n",
        "df_pandas = df_pyspark.toPandas()\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iCNt9--C51cC",
        "outputId": "5b695f81-7aef-47fd-aa21-84d3bcb4293a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Name age Experience Salary\n",
              "0      Krish  31         10  30000\n",
              "1  Sudhanshu  30          8  25000\n",
              "2      Sunny  29          4  20000\n",
              "3       Paul  31          3  20000\n",
              "4     Harsha  21          1  15000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c49d029-2fed-4805-b7c9-8b96b2315ae4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>age</th>\n",
              "      <th>Experience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Krish</td>\n",
              "      <td>31</td>\n",
              "      <td>10</td>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sudhanshu</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Paul</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Harsha</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c49d029-2fed-4805-b7c9-8b96b2315ae4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c49d029-2fed-4805-b7c9-8b96b2315ae4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c49d029-2fed-4805-b7c9-8b96b2315ae4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d83e56fb-301e-4a6f-96dc-530ac347c7e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d83e56fb-301e-4a6f-96dc-530ac347c7e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d83e56fb-301e-4a6f-96dc-530ac347c7e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pandas",
              "summary": "{\n  \"name\": \"df_pandas\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Sam\",\n          \"Sudhanshu\",\n          \"Shubham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"30\",\n          \"23\",\n          \"29\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experience\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"10\",\n          \"8\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Salary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"30000\",\n          \"25000\",\n          \"28000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pandas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PSRvZpQc6JM_",
        "outputId": "5bdeb47c-b8b2-4f28-a9bf-9e62fa3174b4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index.\n",
              "\n",
              "    .. versionchanged:: 0.25.0\n",
              "       If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 475);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **pyspark.sql.functions as F**\n",
        "\n",
        "Importing pyspark.sql.functions as F is a common convention in PySpark for accessing various SQL functions provided by Spark SQL. pyspark.sql.functions contains a wide range of functions that one can use for data manipulation, transformation, aggregation, and more when working with PySpark DataFrames."
      ],
      "metadata": {
        "id": "1ipWZ6dg6a_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F"
      ],
      "metadata": {
        "id": "_5czLRAL71L7"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show DataFrame Content\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjb0tRU876Pl",
        "outputId": "04a186c2-8c75-41c6-a27d-5be654aae66a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 31|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|       Jo| 23|         5| 25000|\n",
            "|      Sam| 21|         4| 28000|\n",
            "|       Li| 29|         1| 15000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting Columns\n",
        "df_selected = df_pyspark.select('Name', 'age', 'Salary')\n",
        "df_selected.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHl9Di-G8eNh",
        "outputId": "d5eeace8-25f8-49d3-fabe-a565424d0717"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+------+\n",
            "|     Name|age|Salary|\n",
            "+---------+---+------+\n",
            "|    Krish| 31| 30000|\n",
            "|Sudhanshu| 30| 25000|\n",
            "|    Sunny| 29| 20000|\n",
            "|     Paul| 31| 20000|\n",
            "|   Harsha| 21| 15000|\n",
            "|  Shubham| 23| 18000|\n",
            "|       Jo| 23| 25000|\n",
            "|      Sam| 21| 28000|\n",
            "|       Li| 29| 15000|\n",
            "+---------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering Rows\n",
        "df_filtered = df_pyspark.filter(df_pyspark['age'] > 29)\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wB3z3P-8qMA",
        "outputId": "bbe732c7-d44f-477f-a13d-6f96de641e9e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|     Paul| 31|         3| 20000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping and Aggregating\n",
        "df_grouped = df_pyspark.groupBy('Experience').agg({'Salary': 'sum'})\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZoIsnsX80E-",
        "outputId": "07067bea-313b-4826-8849-d5518f0eb9c2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Experience|sum(Salary)|\n",
            "+----------+-----------+\n",
            "|         3|    20000.0|\n",
            "|         8|    25000.0|\n",
            "|         5|    25000.0|\n",
            "|         1|    30000.0|\n",
            "|        10|    30000.0|\n",
            "|         4|    48000.0|\n",
            "|         2|    18000.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Experience' and aggregate 'Salary' by sum\n",
        "df_grouped = df_pyspark.groupBy('Experience').agg({'Salary': 'sum'})\n",
        "\n",
        "#Show the grouped and aggregated DataFrame\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPOXjmLk9fQy",
        "outputId": "50134d56-2237-4f23-f545-51a1cccd5345"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Experience|sum(Salary)|\n",
            "+----------+-----------+\n",
            "|         3|    20000.0|\n",
            "|         8|    25000.0|\n",
            "|         5|    25000.0|\n",
            "|         1|    30000.0|\n",
            "|        10|    30000.0|\n",
            "|         4|    48000.0|\n",
            "|         2|    18000.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the result in descending order based on the sum of 'Salary'\n",
        "df_grouped = df_grouped.orderBy(df_grouped['sum(Salary)'].desc())\n",
        "\n",
        "# Show the grouped and aggregated DataFrame\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YgCigXq-HUg",
        "outputId": "c97a8230-bfec-48d1-8c19-28edbbe136c3"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Experience|sum(Salary)|\n",
            "+----------+-----------+\n",
            "|         4|    48000.0|\n",
            "|         1|    30000.0|\n",
            "|        10|    30000.0|\n",
            "|         8|    25000.0|\n",
            "|         5|    25000.0|\n",
            "|         3|    20000.0|\n",
            "|         2|    18000.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting\n",
        "df_sorted = df_pyspark.orderBy('Experience')\n",
        "df_sorted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrS2fZEEHDbX",
        "outputId": "9beff177-560d-481b-dc31-bfbf8b04e9ab"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|       Li| 29|         1| 15000|\n",
            "|    Krish| 31|        10| 30000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     Paul| 31|         3| 20000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|      Sam| 21|         4| 28000|\n",
            "|       Jo| 23|         5| 25000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozvb7WxyHDeG",
        "outputId": "8aed8f47-1d03-432b-e14c-c2e08785d123"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'),\n",
              " ('age', 'string'),\n",
              " ('Experience', 'string'),\n",
              " ('Salary', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert data types to integer\n",
        "df_pyspark = df_pyspark.withColumn('age', df_pyspark['age'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('Experience', df_pyspark['Experience'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('Salary', df_pyspark['Salary'].cast('int'))"
      ],
      "metadata": {
        "id": "aYMc257xHDje"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LADhsnA2HDl9",
        "outputId": "601c7026-3eda-4a8d-9f1e-e67931719c2e"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting\n",
        "df_sorted = df_pyspark.orderBy('Experience')\n",
        "df_sorted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u67C2kWCI5ZQ",
        "outputId": "3939b0f5-33cd-46ed-e534-906c2e0cae57"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|       Li| 29|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     Paul| 31|         3| 20000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|      Sam| 21|         4| 28000|\n",
            "|       Jo| 23|         5| 25000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Krish| 31|        10| 30000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joins\n",
        "other_df = sparkSession.createDataFrame([(21, 'Adi'), (22, 'Bob'),(23, 'Charli'),(21, 'Jay'), (62, 'Mike')], ['age', 'Name'])\n",
        "other_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi08MkEqJJ83",
        "outputId": "c709ee18-11c2-4446-ad52-74afe7d567d9"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "|age|  Name|\n",
            "+---+------+\n",
            "| 21|   Adi|\n",
            "| 22|   Bob|\n",
            "| 23|Charli|\n",
            "| 21|   Jay|\n",
            "| 62|  Mike|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_pyspark.join(other_df, 'age')\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gVSuavEKQbu",
        "outputId": "62d4e2af-f614-4cd0-b59a-0f0ca841a2d3"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----------+------+------+\n",
            "|age|   Name|Experience|Salary|  Name|\n",
            "+---+-------+----------+------+------+\n",
            "| 21|    Sam|         4| 28000|   Adi|\n",
            "| 21| Harsha|         1| 15000|   Adi|\n",
            "| 23|     Jo|         5| 25000|Charli|\n",
            "| 23|Shubham|         2| 18000|Charli|\n",
            "| 21|    Sam|         4| 28000|   Jay|\n",
            "| 21| Harsha|         1| 15000|   Jay|\n",
            "+---+-------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_pyspark.join(other_df, 'age', how='left')\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Meau8X1Moo3",
        "outputId": "582206a3-668f-46cc-9ed3-8b8f3cece18c"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+----------+------+------+\n",
            "|age|     Name|Experience|Salary|  Name|\n",
            "+---+---------+----------+------+------+\n",
            "| 29|    Sunny|         4| 20000|  NULL|\n",
            "| 29|       Li|         1| 15000|  NULL|\n",
            "| 31|    Krish|        10| 30000|  NULL|\n",
            "| 31|     Paul|         3| 20000|  NULL|\n",
            "| 21|   Harsha|         1| 15000|   Jay|\n",
            "| 21|   Harsha|         1| 15000|   Adi|\n",
            "| 21|      Sam|         4| 28000|   Jay|\n",
            "| 21|      Sam|         4| 28000|   Adi|\n",
            "| 30|Sudhanshu|         8| 25000|  NULL|\n",
            "| 23|  Shubham|         2| 18000|Charli|\n",
            "| 23|       Jo|         5| 25000|Charli|\n",
            "+---+---------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Columns\n",
        "from pyspark.sql.functions import when, lit\n",
        "\n",
        "# Add a new column 'Department' with values based on conditions\n",
        "df_with_department = df_pyspark.withColumn('Department',\n",
        "                                           when(df_pyspark['Name'] == 'Krish', lit('Sales'))\n",
        "                                           .when(df_pyspark['Name'] == 'Paul', lit('Marketing'))\n",
        "                                           .when((df_pyspark['Name'] == 'Sam') |\n",
        "                                                 (df_pyspark['Name'] == 'Sunny') |\n",
        "                                                 (df_pyspark['Name'] == 'Jo'), lit('IT'))\n",
        "                                           .otherwise(lit('Other')))\n",
        "# Add a new column 'Education' with values based on conditions\n",
        "df_new = df_with_department.withColumn('Education',\n",
        "                                           when(df_with_department['Name'] == 'Krish', lit('MBA'))\n",
        "                                           .when(df_with_department['Name'] == 'Paul', lit('PhD'))\n",
        "                                           .when((df_with_department['Name'] == 'Sam') |\n",
        "                                                 (df_with_department['Name'] == 'Sunny') |\n",
        "                                                 (df_with_department['Name'] == 'Jo'), lit('Bachelor'))\n",
        "                                           .otherwise(lit('Unknown')))\n",
        "\n",
        "\n",
        "df_new.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpgyYPqQM4Mf",
        "outputId": "054ad0fd-cb02-48a6-cd31-cf5b4b7de0a1"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+----------+---------+\n",
            "|     Name|age|Experience|Salary|Department|Education|\n",
            "+---------+---+----------+------+----------+---------+\n",
            "|    Krish| 31|        10| 30000|     Sales|      MBA|\n",
            "|Sudhanshu| 30|         8| 25000|     Other|  Unknown|\n",
            "|    Sunny| 29|         4| 20000|        IT| Bachelor|\n",
            "|     Paul| 31|         3| 20000| Marketing|      PhD|\n",
            "|   Harsha| 21|         1| 15000|     Other|  Unknown|\n",
            "|  Shubham| 23|         2| 18000|     Other|  Unknown|\n",
            "|       Jo| 23|         5| 25000|        IT| Bachelor|\n",
            "|      Sam| 21|         4| 28000|        IT| Bachelor|\n",
            "|       Li| 29|         1| 15000|     Other|  Unknown|\n",
            "+---------+---+----------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_modified = df_new.drop('age')\n",
        "df_modified.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l9SfgwbSa9Q",
        "outputId": "8e181b7b-c5b3-44ac-9e5b-f1731b1ab339"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+------+----------+---------+\n",
            "|     Name|Experience|Salary|Department|Education|\n",
            "+---------+----------+------+----------+---------+\n",
            "|    Krish|        10| 30000|     Sales|      MBA|\n",
            "|Sudhanshu|         8| 25000|     Other|  Unknown|\n",
            "|    Sunny|         4| 20000|        IT| Bachelor|\n",
            "|     Paul|         3| 20000| Marketing|      PhD|\n",
            "|   Harsha|         1| 15000|     Other|  Unknown|\n",
            "|  Shubham|         2| 18000|     Other|  Unknown|\n",
            "|       Jo|         5| 25000|        IT| Bachelor|\n",
            "|      Sam|         4| 28000|        IT| Bachelor|\n",
            "|       Li|         1| 15000|     Other|  Unknown|\n",
            "+---------+----------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregating Functions\n",
        "row_count = df_modified.count()\n",
        "print(\"Row count:\", row_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCa4OgmhTepc",
        "outputId": "13cc6566-67b7-4df0-e3a7-72ecc7e5c8d9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row count: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using aggregate fun on df col--> gives df after the aggregation\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Row count\n",
        "row_count = df_modified.count()\n",
        "print(\"Row count:\", row_count)\n",
        "\n",
        "# Other aggregation functions\n",
        "# Maximum value of a column\n",
        "max_salary = df_modified.agg(F.max('Salary')).collect()[0][0]\n",
        "print(\"Maximum salary:\", max_salary)\n",
        "\n",
        "# Minimum value of a column\n",
        "min_value = df_modified.agg(F.min('Salary')).collect()[0][0]\n",
        "print(\"Minimum value:\", min_value)\n",
        "\n",
        "# Sum of values in a column\n",
        "sum_value = df_modified.agg(F.sum('Salary')).collect()[0][0]\n",
        "print(\"Sum of values:\", sum_value)\n",
        "\n",
        "# Average value of a column\n",
        "avg_value = df_modified.agg(F.avg('Salary')).collect()[0][0]\n",
        "print(\"Average value:\", avg_value)\n",
        "\n",
        "# Count of non-null values in a column\n",
        "count_non_null = df_modified.agg(F.count('Salary')).collect()[0][0]\n",
        "print(\"Count of non-null values:\", count_non_null)\n",
        "\n",
        "# Count distinct values in a column\n",
        "count_distinct = df_modified.agg(F.countDistinct('Salary')).collect()[0][0]\n",
        "print(\"Count of distinct values:\", count_distinct)\n",
        "\n",
        "# Standard deviation of values in a column\n",
        "std_dev = df_modified.agg(F.stddev('Salary')).collect()[0][0]\n",
        "print(\"Standard deviation:\", std_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTzk-xWWXCdI",
        "outputId": "16833708-de53-439e-a93b-bc58da24d5cf"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row count: 9\n",
            "Maximum salary: 30000\n",
            "Minimum value: 15000\n",
            "Sum of values: 196000\n",
            "Average value: 21777.777777777777\n",
            "Count of non-null values: 9\n",
            "Count of distinct values: 6\n",
            "Standard deviation: 5472.151719794001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does the code: df_modified.agg(F.max('Salary')).collect()[0][0], work?"
      ],
      "metadata": {
        "id": "Hzwa_HSFXRto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modified.agg(F.max('Salary')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a81vD8mcXc6Q",
        "outputId": "97eaa690-e2b6-4ca2-b205-a77c600356e7"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|max(Salary)|\n",
            "+-----------+\n",
            "|      30000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_row_format=df_modified.agg(F.max('Salary')).collect()[0]\n",
        "max_row_format # It gives a list of values ( array)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7MOHGxIXh63",
        "outputId": "df651d67-a16c-4253-b3c0-f8ef4fd213bc"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(max(Salary)=30000)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_row_format[0] # It just gives a single max value."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I9SGF47XpXH",
        "outputId": "8a6a8778-3862-48da-b724-5451f90b692f"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantiles = df_pyspark.approxQuantile('Salary', [0.25, 0.5, 0.75], 0.05)\n",
        "print(\"Quantiles:\", quantiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK-MtfAnXtF3",
        "outputId": "086011f5-630c-462c-e449-ec6a4af34f97"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantiles: [18000.0, 20000.0, 25000.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing DataFrames\n",
        "df_pyspark.write.format('csv').save('output_folder_csv')\n",
        "df_pyspark.write.format('parquet').save('output_folder_parquet') #store and process large amounts of data by organizing data into columns rather than rows."
      ],
      "metadata": {
        "id": "5hPGAVuhYmGf"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop SparkSession\n",
        "sparkSession.stop()"
      ],
      "metadata": {
        "id": "wvJAvYE_Yre2"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ByQkncBY-Sm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}